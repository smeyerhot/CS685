{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"biobert.ipynb","provenance":[],"collapsed_sections":[],"background_execution":"on","authorship_tag":"ABX9TyNdCkoy7FufYbOKBczxHv5K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c18ef2fc92c54c44bd1b39430575fe73":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bb95f1b4398142fb8221b36418e3a5ec","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_30e11d0ae8694774a6c332db8dda6fe1","IPY_MODEL_01396affc99b43ccb999ff5bcc902f31","IPY_MODEL_00dae71754db49658d62b4e5add1fcef"]}},"bb95f1b4398142fb8221b36418e3a5ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30e11d0ae8694774a6c332db8dda6fe1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7e3d7665764b4796971678e09dda8aec","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3eaaf661d8434ee4a287c6ee49d328ac"}},"01396affc99b43ccb999ff5bcc902f31":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_243492ee19de498c85e4056bffa987f5","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":3489,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3489,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7272c7e23b0d477eb8353172c3a88c02"}},"00dae71754db49658d62b4e5add1fcef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0c951f9c1fcd411aaae7f7a32fa7757c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 12.2k/? [00:00&lt;00:00, 298kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05fd44f944f542268b0b3d155f57bbf2"}},"7e3d7665764b4796971678e09dda8aec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3eaaf661d8434ee4a287c6ee49d328ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"243492ee19de498c85e4056bffa987f5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7272c7e23b0d477eb8353172c3a88c02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0c951f9c1fcd411aaae7f7a32fa7757c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"05fd44f944f542268b0b3d155f57bbf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f076c211f19c4a4ea7c851a545146a07":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_995c5984276e48e88da4775e86fd4b62","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6c5fb7c26aad4dac829d28e1f934bd17","IPY_MODEL_e9c28e1a185b4eb688c5e18c8c6587ef","IPY_MODEL_10333070da2f46139eeccf19f2f5744a"]}},"995c5984276e48e88da4775e86fd4b62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c5fb7c26aad4dac829d28e1f934bd17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b6b03e4cb0f041c9b8fab55b5ffb4863","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b80c3216fb3b43f7b589cd40287a7a8c"}},"e9c28e1a185b4eb688c5e18c8c6587ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_37ba440cfa0341f29e4396ec460958c7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":805,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":805,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cc6e518c628d405ba187650fc7cc4f96"}},"10333070da2f46139eeccf19f2f5744a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3bd6793d524b41f6864291024b614a13","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3.12k/? [00:00&lt;00:00, 105kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fc7703d09bc54ac589ca8293835fd07e"}},"b6b03e4cb0f041c9b8fab55b5ffb4863":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b80c3216fb3b43f7b589cd40287a7a8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"37ba440cfa0341f29e4396ec460958c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cc6e518c628d405ba187650fc7cc4f96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3bd6793d524b41f6864291024b614a13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fc7703d09bc54ac589ca8293835fd07e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9bbc4c78a5c549d2959ca6382463ec93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4aed8ab1ae284f7587486ae57f16a051","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0a1d112ed6364f11af2b6ec9c52b6836","IPY_MODEL_6fe1f99ddbeb4197a0550fc71912ddd6","IPY_MODEL_ffb32eb4bc10438197ebc278b0940f57"]}},"4aed8ab1ae284f7587486ae57f16a051":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0a1d112ed6364f11af2b6ec9c52b6836":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2f1a82a159264a6eaedb0c47a97d016f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_87c20a0770b04a41aab3aa38acb8a080"}},"6fe1f99ddbeb4197a0550fc71912ddd6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_584fddb05aef416fa14290b0722c5486","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5048ddc815534234918f8c78882441a2"}},"ffb32eb4bc10438197ebc278b0940f57":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2e739c08f1ae4d2a81858a2dbafed4e0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456/0 [00:00&lt;00:00, 4557.17 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5cfeb0e093274d57a30c1bcf24854081"}},"2f1a82a159264a6eaedb0c47a97d016f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"87c20a0770b04a41aab3aa38acb8a080":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"584fddb05aef416fa14290b0722c5486":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5048ddc815534234918f8c78882441a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2e739c08f1ae4d2a81858a2dbafed4e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5cfeb0e093274d57a30c1bcf24854081":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"538d1c5c5f694fa29ff86448c543eb05":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3dae121c755141e082719e7534d4275f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_df3d5aa4db844cb2ad38778dab6faa3f","IPY_MODEL_c8096f29b3634be5a05b62780ce19317","IPY_MODEL_54c4a149087b4c29ba1ee7349d0350e1"]}},"3dae121c755141e082719e7534d4275f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df3d5aa4db844cb2ad38778dab6faa3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b23dbf17f4274f669d0e47bd09b6e6ae","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_80e412de076a4f4f9c6041b6f83d9503"}},"c8096f29b3634be5a05b62780ce19317":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6977b767e50c4d5b84bb603955025ec7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c61b6587904f424ca8d0c222a8cc4612"}},"54c4a149087b4c29ba1ee7349d0350e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1198d2c2354542aeb377bab2aab4baf2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00, 30.39it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_42c5cf87454246af8dc360c74514a2b8"}},"b23dbf17f4274f669d0e47bd09b6e6ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"80e412de076a4f4f9c6041b6f83d9503":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6977b767e50c4d5b84bb603955025ec7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c61b6587904f424ca8d0c222a8cc4612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1198d2c2354542aeb377bab2aab4baf2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"42c5cf87454246af8dc360c74514a2b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6296060ac34b4fc48976422b96193a82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_65c2a9ddf70f4be5aba492509fb5ed89","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6ad4b6b8bfef4f41bc1b92a80be12986","IPY_MODEL_56fda0238f2d4b4cb213373ef3aa9223","IPY_MODEL_be44805863d94c919ffb92c75d315e5e"]}},"65c2a9ddf70f4be5aba492509fb5ed89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6ad4b6b8bfef4f41bc1b92a80be12986":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cd8676ca382d4fa59957acc1df189367","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f073ffaf8af349b5b3306d534e5fb0c2"}},"56fda0238f2d4b4cb213373ef3aa9223":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8972b94b03354b6e843fd76e310c750f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":313,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":313,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e86b54a422094a459700cca7640d8cc4"}},"be44805863d94c919ffb92c75d315e5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2eb42f288cdf459b8c05954ec95ccd8a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 313/313 [00:00&lt;00:00, 9.66kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e01f8694f3e4c1d92e31f2c0c3a1fa8"}},"cd8676ca382d4fa59957acc1df189367":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f073ffaf8af349b5b3306d534e5fb0c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8972b94b03354b6e843fd76e310c750f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e86b54a422094a459700cca7640d8cc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2eb42f288cdf459b8c05954ec95ccd8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3e01f8694f3e4c1d92e31f2c0c3a1fa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c582c90cfd88448991b368eb1939e64c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_691a62ac52a5488789bcbff0d80a8b6e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5a70af24e5814e8f861c8680c1cc79c4","IPY_MODEL_8db9bfc1956547a2a8560fdb5c5296ef","IPY_MODEL_71dcb2ba7c7e48c5bdae4cfb9c386d71"]}},"691a62ac52a5488789bcbff0d80a8b6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5a70af24e5814e8f861c8680c1cc79c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c38f7c96f5b548a58537ddaee6c8198c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e166c465d8d3440d98903b39b021ebfe"}},"8db9bfc1956547a2a8560fdb5c5296ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_efead835c3af43a9ad317fef7941f5d1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dc381f271921494db99bf4f613932209"}},"71dcb2ba7c7e48c5bdae4cfb9c386d71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4e5db583d7a8447ebfaa52fc62be2251","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 208k/208k [00:00&lt;00:00, 195kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_231e71aac67c4eeb98f6d4e09f8886cf"}},"c38f7c96f5b548a58537ddaee6c8198c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e166c465d8d3440d98903b39b021ebfe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"efead835c3af43a9ad317fef7941f5d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dc381f271921494db99bf4f613932209":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4e5db583d7a8447ebfaa52fc62be2251":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"231e71aac67c4eeb98f6d4e09f8886cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91ad1505848e4c86ac700859d894e900":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_88a25cf2a33e4af7945d5c505b246c8b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e6cdf79bbfbf40a8be3a76c4d091dfb0","IPY_MODEL_31fc506a8bbc4595ac45d9c56ed2ce5a","IPY_MODEL_2b37b2b7ed254f5eb2552f6ebf2ae2ab"]}},"88a25cf2a33e4af7945d5c505b246c8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e6cdf79bbfbf40a8be3a76c4d091dfb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eeae78a1313c402bb4e07e2d34a0cc02","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33881f123edd4b79af5072a66e94665e"}},"31fc506a8bbc4595ac45d9c56ed2ce5a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6be6e9f932974ce3b12607f76f5fd982","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":435780550,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435780550,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4c5962d7973449f98e6a3288c4b52474"}},"2b37b2b7ed254f5eb2552f6ebf2ae2ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4b3a6d4e255347fd8b32bd2a27379d0d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 416M/416M [00:09&lt;00:00, 53.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9f13edf7bd544b6bc7805cdce65954a"}},"eeae78a1313c402bb4e07e2d34a0cc02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"33881f123edd4b79af5072a66e94665e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6be6e9f932974ce3b12607f76f5fd982":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4c5962d7973449f98e6a3288c4b52474":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4b3a6d4e255347fd8b32bd2a27379d0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a9f13edf7bd544b6bc7805cdce65954a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"X5tU190hjG5n"},"source":["# GitHub Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UOP7j4_yN-Zm","executionInfo":{"status":"ok","timestamp":1639082608497,"user_tz":300,"elapsed":14253,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"d0b1fd50-df8e-4860-ae66-fc6e403dc784"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","metadata":{"id":"DxWMZVAOODu3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639082611447,"user_tz":300,"elapsed":235,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"e9a03963-12a4-4bb9-be84-c72695d2fc7b"},"source":["%cd '/content/drive/MyDrive/CS685'"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CS685\n"]}]},{"cell_type":"code","metadata":{"id":"xskXig5-iUJT","executionInfo":{"status":"ok","timestamp":1639082612683,"user_tz":300,"elapsed":105,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}}},"source":["TOKEN=\"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\"\n","USER=\"smeyerhot\"\n","PROJECT=\"CS685\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"F9lv4FakiZzn","executionInfo":{"status":"ok","timestamp":1639082613675,"user_tz":300,"elapsed":123,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}}},"source":["GIT_PATH = \"https://\" + TOKEN + \"@github.com/\" + USER + \"/\" + PROJECT + \".git\""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0Tq4ktPigBC","executionInfo":{"status":"ok","timestamp":1639082623087,"user_tz":300,"elapsed":8486,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"cc726c71-add3-4cde-8234-a78722dc16b0"},"source":["!git pull \"{GIT_PATH}\" "],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["From https://github.com/smeyerhot/CS685\n"," * branch            HEAD       -> FETCH_HEAD\n","Already up to date.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1YQH4e6zgJ7J","executionInfo":{"status":"ok","timestamp":1639082010040,"user_tz":300,"elapsed":19342,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"c3ffd5ba-52a3-44d7-bf85-b9c698e53f24"},"source":["!git checkout biobert # or -b"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["M\t__pycache__/data.cpython-37.pyc\n","M\tbaseline-augmented.ipynb\n","M\tbiobert.ipynb\n","M\tprefix.ipynb\n","Already on 'biobert'\n"]}]},{"cell_type":"code","metadata":{"id":"d-yBePOT4G6_"},"source":["# !git add --all\n","# !git config --global user.email \"psalm10045@gmail.com\"\n","# !git commit -m 'update biobert-gpt2'\n","# !git push \"{GIT_PATH}\" \n","# !git status"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XobQ_hWqiosG"},"source":["# BioBERT Embedding Extraction"]},{"cell_type":"markdown","metadata":{"id":"yKF6IUV81Tjm"},"source":["## Environment setup"]},{"cell_type":"code","metadata":{"id":"zfZv-Q-DhD0W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639082038310,"user_tz":300,"elapsed":22649,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"9172b281-e4ce-48e7-fb7f-edcdc39f27f4"},"source":["!pip install transformers datasets\n","!pip install pytorch_pretrained_bert\n","!pip install rouge/requirements.txt\n","!pip install rouge-score"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 2.0 MB/s \n","\u001b[?25hCollecting datasets\n","  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n","\u001b[K     |████████████████████████████████| 298 kB 67.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 682 kB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 29.0 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 74.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 80.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 72.5 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 68.2 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 70.7 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 72.0 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.8)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n","\u001b[K     |████████████████████████████████| 192 kB 74.8 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 71.9 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, sacremoses, huggingface-hub, transformers, datasets\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 datasets-1.16.1 frozenlist-1.2.0 fsspec-2021.11.1 huggingface-hub-0.2.1 multidict-5.2.0 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.13.0 xxhash-2.0.2 yarl-1.7.2\n","Collecting pytorch_pretrained_bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 2.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.62.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n","Collecting boto3\n","  Downloading boto3-1.20.22-py3-none-any.whl (131 kB)\n","\u001b[K     |████████████████████████████████| 131 kB 13.0 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.10.0.2)\n","Collecting botocore<1.24.0,>=1.23.22\n","  Downloading botocore-1.23.23-py3-none-any.whl (8.4 MB)\n","\u001b[K     |████████████████████████████████| 8.4 MB 24.5 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 10.0 MB/s \n","\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.22->boto3->pytorch_pretrained_bert) (2.8.2)\n","Collecting urllib3<1.27,>=1.25.4\n","  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 78.9 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.22->boto3->pytorch_pretrained_bert) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 76.3 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.10.8)\n","Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed boto3-1.20.22 botocore-1.23.23 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.0 urllib3-1.25.11\n","\u001b[31mERROR: Invalid requirement: 'rouge/requirements.txt'\n","Hint: It looks like a path. File 'rouge/requirements.txt' does not exist.\u001b[0m\n","Collecting rouge-score\n","  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.19.5)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge-score) (3.2.5)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.0.4\n"]}]},{"cell_type":"code","metadata":{"id":"Fbmyt_oa0jeN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639082052992,"user_tz":300,"elapsed":11109,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"ef9546cc-d220-4286-fe65-0b36ce8edded"},"source":["import os\n","import time\n","\n","import json\n","import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import random\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n","\n","from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer, AdamW, GPT2LMHeadModel, \\\n","GPT2DoubleHeadsModel, GPT2TokenizerFast, GPT2Config, BertTokenizer, EncoderDecoderModel\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","from datasets import load_dataset\n","\n","from helper import format_time, rouge\n","from data import GPT2Dataset, preprocessing, split_data\n","from plots import loss_curves\n","\n","import nltk\n","nltk.download('punkt')"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ThjqniuCw7n1","executionInfo":{"status":"ok","timestamp":1639082061774,"user_tz":300,"elapsed":368,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"c8bab6e0-4764-4348-ad12-b4e79ea33c34"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"markdown","metadata":{"id":"yu2AkxYb1ZFQ"},"source":["## Data Augmentation"]},{"cell_type":"code","metadata":{"id":"MDPxV7r11SJH","colab":{"base_uri":"https://localhost:8080/","height":187,"referenced_widgets":["c18ef2fc92c54c44bd1b39430575fe73","bb95f1b4398142fb8221b36418e3a5ec","30e11d0ae8694774a6c332db8dda6fe1","01396affc99b43ccb999ff5bcc902f31","00dae71754db49658d62b4e5add1fcef","7e3d7665764b4796971678e09dda8aec","3eaaf661d8434ee4a287c6ee49d328ac","243492ee19de498c85e4056bffa987f5","7272c7e23b0d477eb8353172c3a88c02","0c951f9c1fcd411aaae7f7a32fa7757c","05fd44f944f542268b0b3d155f57bbf2","f076c211f19c4a4ea7c851a545146a07","995c5984276e48e88da4775e86fd4b62","6c5fb7c26aad4dac829d28e1f934bd17","e9c28e1a185b4eb688c5e18c8c6587ef","10333070da2f46139eeccf19f2f5744a","b6b03e4cb0f041c9b8fab55b5ffb4863","b80c3216fb3b43f7b589cd40287a7a8c","37ba440cfa0341f29e4396ec460958c7","cc6e518c628d405ba187650fc7cc4f96","3bd6793d524b41f6864291024b614a13","fc7703d09bc54ac589ca8293835fd07e","9bbc4c78a5c549d2959ca6382463ec93","4aed8ab1ae284f7587486ae57f16a051","0a1d112ed6364f11af2b6ec9c52b6836","6fe1f99ddbeb4197a0550fc71912ddd6","ffb32eb4bc10438197ebc278b0940f57","2f1a82a159264a6eaedb0c47a97d016f","87c20a0770b04a41aab3aa38acb8a080","584fddb05aef416fa14290b0722c5486","5048ddc815534234918f8c78882441a2","2e739c08f1ae4d2a81858a2dbafed4e0","5cfeb0e093274d57a30c1bcf24854081","538d1c5c5f694fa29ff86448c543eb05","3dae121c755141e082719e7534d4275f","df3d5aa4db844cb2ad38778dab6faa3f","c8096f29b3634be5a05b62780ce19317","54c4a149087b4c29ba1ee7349d0350e1","b23dbf17f4274f669d0e47bd09b6e6ae","80e412de076a4f4f9c6041b6f83d9503","6977b767e50c4d5b84bb603955025ec7","c61b6587904f424ca8d0c222a8cc4612","1198d2c2354542aeb377bab2aab4baf2","42c5cf87454246af8dc360c74514a2b8"]},"executionInfo":{"status":"ok","timestamp":1639082079437,"user_tz":300,"elapsed":3161,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"2d4f3d0d-f363-48ba-b6cf-79d092391fbc"},"source":["covid_dialog = load_dataset(\"covid_qa_ucsd\", \"en\", data_dir=\"/content/drive/MyDrive/CS685\" )"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c18ef2fc92c54c44bd1b39430575fe73","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/3.49k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f076c211f19c4a4ea7c851a545146a07","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/805 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using custom data configuration en-c080136eb0615511\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset covid_qa_ucsd/en (download: Unknown size, generated: 473.58 KiB, post-processed: Unknown size, total: 473.58 KiB) to /root/.cache/huggingface/datasets/covid_qa_ucsd/en-c080136eb0615511/1.0.0/2a15b6e8fdc7cee91951d8f20ac2b26ede79fbef988919fbde22dbb97bf4df81...\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9bbc4c78a5c549d2959ca6382463ec93","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset covid_qa_ucsd downloaded and prepared to /root/.cache/huggingface/datasets/covid_qa_ucsd/en-c080136eb0615511/1.0.0/2a15b6e8fdc7cee91951d8f20ac2b26ede79fbef988919fbde22dbb97bf4df81. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"538d1c5c5f694fa29ff86448c543eb05","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"DuNo9WV51jdA","executionInfo":{"status":"ok","timestamp":1639082081571,"user_tz":300,"elapsed":260,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}}},"source":["covid_df = covid_dialog['train'].to_pandas()"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-sh955la1tdQ","executionInfo":{"status":"ok","timestamp":1639082082858,"user_tz":300,"elapsed":5,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"9d453ac7-6ce0-4d92-a3c2-a918037811d1"},"source":["qa_df = preprocessing(covid_df)\n","text = qa_df.text.copy()"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS685/data.py:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  all_fields = np.transpose(np.array(all_fields).reshape((4, -1)))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"4svGW1vDBsoT","executionInfo":{"status":"ok","timestamp":1639082084447,"user_tz":300,"elapsed":7,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"f914cf2f-b419-4449-c80e-ee167dea266a"},"source":["qa_df.head()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>encoder</th>\n","      <th>decoder</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[I have cough with no travel history. Is this ...</td>\n","      <td>[Hello, I understand your concern. I just have...</td>\n","      <td>[I have cough with no travel history. Is this ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>[I have cough with no travel history. Is this ...</td>\n","      <td>[Hi, I would recommend you take n-acetylcystei...</td>\n","      <td>[I have cough with no travel history. Is this ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>[I have a little fever with no history of fore...</td>\n","      <td>[Hello, I can understand your concern.In my op...</td>\n","      <td>[I have a little fever with no history of fore...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>[I have a little fever with no history of fore...</td>\n","      <td>[Hi, yes, upload in this query only. I will se...</td>\n","      <td>[I have a little fever with no history of fore...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>[I have a little fever with no history of fore...</td>\n","      <td>[Hi, I can understand your concern. I have gon...</td>\n","      <td>[I have a little fever with no history of fore...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  id  ...                                               text\n","0  0  ...  [I have cough with no travel history. Is this ...\n","1  0  ...  [I have cough with no travel history. Is this ...\n","2  1  ...  [I have a little fever with no history of fore...\n","3  1  ...  [I have a little fever with no history of fore...\n","4  1  ...  [I have a little fever with no history of fore...\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## Additional Preprocessing"],"metadata":{"id":"Hjytw33sWz5E"}},{"cell_type":"code","source":["qa_df['encoder_str'] = qa_df['encoder'].apply(lambda x: ''.join(map(str, x)))\n","qa_df['decoder_str'] = qa_df['decoder'].apply(lambda x: ''.join(map(str, x)))"],"metadata":{"id":"QPzyihvAXhpg","executionInfo":{"status":"ok","timestamp":1639082086932,"user_tz":300,"elapsed":2,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["qa_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"KhQ7NTwUXxzX","executionInfo":{"status":"ok","timestamp":1639082088367,"user_tz":300,"elapsed":8,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"3f3c2ef2-e5c8-4c62-f11d-377fe262b3de"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>encoder</th>\n","      <th>decoder</th>\n","      <th>text</th>\n","      <th>encoder_str</th>\n","      <th>decoder_str</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[I have cough with no travel history. Is this ...</td>\n","      <td>[Hello, I understand your concern. I just have...</td>\n","      <td>[I have cough with no travel history. Is this ...</td>\n","      <td>I have cough with no travel history. Is this a...</td>\n","      <td>Hello, I understand your concern. I just have ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>[I have cough with no travel history. Is this ...</td>\n","      <td>[Hi, I would recommend you take n-acetylcystei...</td>\n","      <td>[I have cough with no travel history. Is this ...</td>\n","      <td>I have cough with no travel history. Is this a...</td>\n","      <td>Hi, I would recommend you take n-acetylcystein...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>[I have a little fever with no history of fore...</td>\n","      <td>[Hello, I can understand your concern.In my op...</td>\n","      <td>[I have a little fever with no history of fore...</td>\n","      <td>I have a little fever with no history of forei...</td>\n","      <td>Hello, I can understand your concern.In my opi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>[I have a little fever with no history of fore...</td>\n","      <td>[Hi, yes, upload in this query only. I will se...</td>\n","      <td>[I have a little fever with no history of fore...</td>\n","      <td>I have a little fever with no history of forei...</td>\n","      <td>Hi, yes, upload in this query only. I will see...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>[I have a little fever with no history of fore...</td>\n","      <td>[Hi, I can understand your concern. I have gon...</td>\n","      <td>[I have a little fever with no history of fore...</td>\n","      <td>I have a little fever with no history of forei...</td>\n","      <td>Hi, I can understand your concern. I have gone...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  id  ...                                        decoder_str\n","0  0  ...  Hello, I understand your concern. I just have ...\n","1  0  ...  Hi, I would recommend you take n-acetylcystein...\n","2  1  ...  Hello, I can understand your concern.In my opi...\n","3  1  ...  Hi, yes, upload in this query only. I will see...\n","4  1  ...  Hi, I can understand your concern. I have gone...\n","\n","[5 rows x 6 columns]"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"su7iVCAlKo5R"},"source":["## Load Models & Setup"]},{"cell_type":"markdown","source":["### Maximum Length"],"metadata":{"id":"FLzMKiLtbznt"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"id":"gYyLJvI8Lgna","executionInfo":{"status":"ok","timestamp":1639082092182,"user_tz":300,"elapsed":851,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"d593217a-78fb-4c92-ef47-4a346b3083df"},"source":["doc_lengths = []\n","\n","for bio in text:\n","  \n","    # get rough token count distribution\n","    tokens = nltk.word_tokenize(bio[0])\n","\n","    doc_lengths.append(len(tokens))\n","\n","doc_lengths = np.array(doc_lengths)\n","\n","\n","sns.distplot(doc_lengths) # Most of them are within 500, so we can set the MAX_LENGTH = 500 (or 512)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n","  warnings.warn(msg, FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f3c2bf7f250>"]},"metadata":{},"execution_count":16},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["qa_df['encoder_len']=qa_df['encoder_str'].apply(lambda x: len(x.split(' ')))\n","qa_df['decoder_len']=qa_df['decoder_str'].apply(lambda x: len(x.split(' ')))"],"metadata":{"id":"S_gpgN17jjql","executionInfo":{"status":"ok","timestamp":1639082094345,"user_tz":300,"elapsed":446,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["for i in range(0,101,10):\n","  print(i,np.percentile(qa_df.encoder_len,i),np.percentile(qa_df.decoder_len,i))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_Hs7xVWjanj","executionInfo":{"status":"ok","timestamp":1639082095692,"user_tz":300,"elapsed":4,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"95f5c162-d434-41e4-a42d-a54801ac2547"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["0 7.0 1.0\n","10 27.0 25.0\n","20 39.0 35.0\n","30 51.0 43.0\n","40 59.0 52.0\n","50 70.0 59.0\n","60 79.0 66.0\n","70 85.39999999999998 72.0\n","80 93.0 84.0\n","90 105.0 90.80000000000007\n","100 2451.0 247.0\n"]}]},{"cell_type":"code","source":["for i in range(90,101,1):\n","  print(i,np.percentile(qa_df.encoder_len,i),np.percentile(qa_df.decoder_len,i))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IChBrt3LkBwU","executionInfo":{"status":"ok","timestamp":1639082097028,"user_tz":300,"elapsed":4,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"f368ddc6-09c1-4e51-9d33-b0841b8e8685"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["90 105.0 90.80000000000007\n","91 109.0 93.0\n","92 111.0 94.0\n","93 115.25999999999999 96.0\n","94 126.0 97.15999999999985\n","95 144.89999999999998 100.89999999999998\n","96 161.48000000000025 106.32000000000016\n","97 188.07999999999993 111.53999999999996\n","98 263.5200000000001 124.80000000000007\n","99 482.57999999997844 159.7199999999998\n","100 2451.0 247.0\n"]}]},{"cell_type":"markdown","source":["Since 99% of encoder and 100% of decoders are within length of 500, we set the maximum length to be 500. "],"metadata":{"id":"rOsGsNw8koKH"}},{"cell_type":"markdown","source":["### BioBERT Tokenizer & Model "],"metadata":{"id":"xLSRIc2WbnBy"}},{"cell_type":"code","metadata":{"id":"C414MAm_PU5t","executionInfo":{"status":"ok","timestamp":1639082100169,"user_tz":300,"elapsed":268,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}}},"source":["import logging\n","logging.basicConfig(level=logging.INFO)"],"execution_count":20,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"9nJ-kvwgJ8Dv","executionInfo":{"status":"ok","timestamp":1639082103561,"user_tz":300,"elapsed":3,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206,"referenced_widgets":["6296060ac34b4fc48976422b96193a82","65c2a9ddf70f4be5aba492509fb5ed89","6ad4b6b8bfef4f41bc1b92a80be12986","56fda0238f2d4b4cb213373ef3aa9223","be44805863d94c919ffb92c75d315e5e","cd8676ca382d4fa59957acc1df189367","f073ffaf8af349b5b3306d534e5fb0c2","8972b94b03354b6e843fd76e310c750f","e86b54a422094a459700cca7640d8cc4","2eb42f288cdf459b8c05954ec95ccd8a","3e01f8694f3e4c1d92e31f2c0c3a1fa8","c582c90cfd88448991b368eb1939e64c","691a62ac52a5488789bcbff0d80a8b6e","5a70af24e5814e8f861c8680c1cc79c4","8db9bfc1956547a2a8560fdb5c5296ef","71dcb2ba7c7e48c5bdae4cfb9c386d71","c38f7c96f5b548a58537ddaee6c8198c","e166c465d8d3440d98903b39b021ebfe","efead835c3af43a9ad317fef7941f5d1","dc381f271921494db99bf4f613932209","4e5db583d7a8447ebfaa52fc62be2251","231e71aac67c4eeb98f6d4e09f8886cf","91ad1505848e4c86ac700859d894e900","88a25cf2a33e4af7945d5c505b246c8b","e6cdf79bbfbf40a8be3a76c4d091dfb0","31fc506a8bbc4595ac45d9c56ed2ce5a","2b37b2b7ed254f5eb2552f6ebf2ae2ab","eeae78a1313c402bb4e07e2d34a0cc02","33881f123edd4b79af5072a66e94665e","6be6e9f932974ce3b12607f76f5fd982","4c5962d7973449f98e6a3288c4b52474","4b3a6d4e255347fd8b32bd2a27379d0d","a9f13edf7bd544b6bc7805cdce65954a"]},"id":"fPYQK1qNXD99","executionInfo":{"status":"ok","timestamp":1639082145662,"user_tz":300,"elapsed":37106,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"f3584233-53a8-46d1-d2c6-c8d2281ccf43"},"source":["biobert_tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n","biobert_model = AutoModelForCausalLM.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", output_hidden_states=True).cuda()"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6296060ac34b4fc48976422b96193a82","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/313 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c582c90cfd88448991b368eb1939e64c","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91ad1505848e4c86ac700859d894e900","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n","Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["biobert_model.cuda()"],"metadata":{"id":"rtUBLAq5sb5b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids_encoder = []\n","attention_masks_encoder = []\n","\n","input_ids_decoder = []\n","attention_masks_decoder = []\n","\n","# For every sentence...\n","for sent in qa_df['encoder_str']:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict_encoder = biobert_tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 500,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids_encoder.append(encoded_dict_encoder['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks_encoder.append(encoded_dict_encoder['attention_mask'])\n","\n","\n","for sent in qa_df['decoder_str']:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict_decoder = biobert_tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 500,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids_decoder.append(encoded_dict_decoder['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks_decoder.append(encoded_dict_decoder['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids_encoder = torch.cat(input_ids_encoder, dim=0)\n","attention_masks_encoder = torch.cat(attention_masks_encoder, dim=0)\n","\n","input_ids_decoder = torch.cat(input_ids_decoder, dim=0)\n","attention_masks_decoder = torch.cat(attention_masks_decoder, dim=0)"],"metadata":{"id":"8VfVNhpwzTgz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639082202665,"user_tz":300,"elapsed":2067,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"6e043715-1090-4bbd-bfbf-1855708e4b4e"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"markdown","source":["### Extract BioBERT embeddings for each encoder-decoder pair"],"metadata":{"id":"75qt3js2t49D"}},{"cell_type":"code","source":["biobert_model.to('cpu')"],"metadata":{"id":"en21HARmuNv5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids_encoder = input_ids_encoder.to('cpu')\n","input_ids_encoder = attention_masks_encoder.to('cpu')"],"metadata":{"id":"4ChKRBbUup73","executionInfo":{"status":"ok","timestamp":1639082528999,"user_tz":300,"elapsed":390,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"gSn-r7GOzRzh","executionInfo":{"status":"ok","timestamp":1639082218898,"user_tz":300,"elapsed":243,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"HVscCr0a4v-z","executionInfo":{"status":"ok","timestamp":1639082530440,"user_tz":300,"elapsed":2,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Run the text through BERT, and collect all of the hidden states produced\n","# from all 12 layers. \n","\n","# hidden_states = []\n","\n","# for i in range(input_ids_encoder.shape[0]):\n","#   with torch.no_grad():\n","    \n","#     outputs = biobert_model([input_ids_encoder[i]], [attention_masks_encoder[i]])\n","\n","#     # Evaluating the model will return a different number of objects based on \n","#     # how it's  configured in the `from_pretrained` call earlier. In this case, \n","#     # becase we set `output_hidden_states = True`, the third item will be the \n","#     # hidden states from all layers. See the documentation for more details:\n","#     # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n","#     hidden_states.append(outputs[2])\n","\n","with torch.no_grad():\n","\n","  outputs = biobert_model(input_ids_encoder, attention_masks_encoder)\n","  hidden_states = outputs[2]\n","\n","\n","#hidden_states = torch.tensor(hidden_states)"],"metadata":{"id":"PFybyqp9t30l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"inVDse2Oe_gY"},"source":["### Dataset Loader"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZRhU2O1e-mX","executionInfo":{"status":"ok","timestamp":1638918548120,"user_tz":300,"elapsed":1240,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"1d954ec2-7bd7-4c4c-da80-04b33dedbaf6"},"source":["batch_size = 2\n","\n","unique_vals = qa_df.id[len(qa_df)-1]\n","\n","# Split into training and validation sets\n","train_size = int(0.8 * unique_vals)\n","val_size = int(0.1 * unique_vals)\n","test_size = unique_vals - train_size - val_size\n","\n","train_split, val_split, test_split = split_data(qa_df, [train_size, val_size, test_size])\n","\n","train_split.reset_index(drop=True, inplace=True)\n","val_split.reset_index(drop=True, inplace=True)\n","test_split.reset_index(drop=True, inplace=True)\n","\n","print(train_split.head())\n","\n","print(\"length of dataset: \" + str(unique_vals))\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))\n","print('{:>5,} test samples'.format(test_size))\n","\n","train_dataset = GPT2Dataset(train_split, encoder_tokenizer, decoder_tokenizer, max_length=512, decoder_only=True)\n","val_dataset = GPT2Dataset(val_split, encoder_tokenizer, decoder_tokenizer, max_length=512, decoder_only=True)\n","test_dataset = GPT2Dataset(test_split, encoder_tokenizer, decoder_tokenizer, max_length=512, decoder_only=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["    id  ...                                               text\n","0  187  ...  [I have no termometer for fever cheek.does cov...\n","1  143  ...  [Suggest treatment for pneumonia, vomiting and...\n","2  354  ...  [I have diarrhea and am concerned about covid ...\n","3  444  ...  [Hello, I need to go to my Dr. to get my presc...\n","4  514  ...  [I have pain/discomfort in my lungs. I don't e...\n","\n","[5 rows x 4 columns]\n","length of dataset: 571\n","  456 training samples\n","   57 validation samples\n","   58 test samples\n"]}]},{"cell_type":"code","metadata":{"id":"Lb1FhNH8frip"},"source":["# Create the DataLoaders for our training and validation datasets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DXRts0uMLoCE"},"source":["## Fine-tune BioBERT Models on COVID-Dialogue"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"kcULroH9LpNq","executionInfo":{"status":"error","timestamp":1638918562472,"user_tz":300,"elapsed":1334,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"c99cb21e-ecfd-405e-aa99-6c907bc37776"},"source":["useCuda = True\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-0d2845c0161d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0museCuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     def register_backward_hook(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    896\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 15.90 GiB total capacity; 14.66 GiB already allocated; 43.75 MiB free; 14.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","metadata":{"id":"SBNPNn-TXB0t"},"source":["# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n","# otherwise the tokenizer and model tensors won't match up\n","model.encoder.resize_token_embeddings(len(encoder_tokenizer))\n","model.decoder.resize_token_embeddings(len(decoder_tokenizer))\n","\n","# Tell pytorch to run this model on the GPU.\n","device = torch.device(\"cuda\")\n","model.cuda()\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aWYmc8qaf21o"},"source":["# some parameters I cooked up that work reasonably well\n","epochs = 10\n","learning_rate = 5e-5 #5e-4\n","warmup_steps = 2000 #1e2\n","epsilon = 1e-8\n","\n","# this produces sample output every 100 steps\n","sample_every = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VGiev3fbf_XN"},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","optimizer = AdamW(model.parameters(),\n","                  lr = learning_rate,\n","                  eps = epsilon\n","                )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jeI6ugKgA_A"},"source":["# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","# This changes the learning rate as the training loop progresses\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = warmup_steps, \n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9W3GIZDGgCcq","colab":{"base_uri":"https://localhost:8080/","height":511},"executionInfo":{"status":"error","timestamp":1638918394960,"user_tz":300,"elapsed":10,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"310275a3-6047-43ff-d4bc-669ddde01eac"},"source":["total_t0 = time.time()\n","\n","training_stats = []\n","\n","model = model.to(device)\n","\n","for epoch_i in range(0, epochs):\n","\n","    # ========================================\n","    #               Training\n","    # ========================================\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    t0 = time.time()\n","\n","    total_train_loss = 0\n","\n","    model.train()\n","\n","    for step, batch in enumerate(train_dataloader):\n","\n","        b_input_ids = batch[0].to(device)\n","        b_decoder_input_ids = batch[1].to(device)\n","        b_labels = batch[1].to(device)\n","        b_masks = batch[3].to(device)\n","        b_decoder_masks = batch[4].to(device)\n","        model.zero_grad()        \n","\n","        # print(b_input_ids.shape)\n","        # print(b_masks.shape)\n","        # print(b_decoder_input_ids.shape)\n","\n","        outputs = model(input_ids=b_input_ids,\n","                          labels=b_labels, \n","                          attention_mask=b_masks,\n","                          decoder_input_ids=b_decoder_input_ids,\n","                          decoder_attention_mask=b_decoder_masks,\n","                          token_type_ids=None\n","                        )\n","\n","        loss = outputs[0]  \n","\n","        batch_loss = loss.item()\n","        total_train_loss += batch_loss\n","\n","        # Get sample every x batches.\n","        if step % sample_every == 0 and not step == 0:\n","\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n","\n","            model.eval()\n","\n","            # print(b_input_ids)\n","            # print(b_decoder_input_ids)\n","\n","            sample_outputs = model.generate(\n","                                    input_ids=b_input_ids,\n","                                    # bos_token_id=encoder_tokenizer.bos_token,\n","                                    do_sample=True,   \n","                                    top_k=50, \n","                                    max_length = 200,\n","                                    top_p=0.95, \n","                                    num_return_sequences=1\n","                                )\n","            for i, sample_output in enumerate(sample_outputs):\n","                  print(\"{}: {}\".format(i, decoder_tokenizer.decode(sample_output, skip_special_tokens=True)))\n","            \n","            model.train()\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)       \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    model.eval()\n","\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        #print(b_input_ids.shape)\n","        b_input_ids = batch[0].to(device)\n","        b_decoder_input_ids = batch[1].to(device)\n","        b_labels = batch[1].to(device)\n","        b_masks = batch[3].to(device)\n","        b_decoder_masks = batch[4].to(device)\n","        \n","        with torch.no_grad():        \n","\n","            #print(b_input_ids.shape)\n","            outputs  = model(input_ids=b_input_ids,\n","                          labels=b_labels, \n","                          attention_mask=b_masks,\n","                          decoder_input_ids=b_decoder_input_ids,\n","                          decoder_attention_mask=b_decoder_masks,\n","                          token_type_ids=None\n","                        )\n","          \n","            loss = outputs[0]  \n","            \n","        batch_loss = loss.item()\n","        total_eval_loss += batch_loss        \n","\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    validation_time = format_time(time.time() - t0)    \n","\n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-b5a2d7dd5e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m                           \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_decoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                           \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_decoder_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                           \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                         )\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs_decoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m         )\n\u001b[1;32m   1057\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    892\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m                 )\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m             )\n\u001b[1;32m    425\u001b[0m             \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_attn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upcast_and_reordered_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m_attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 15.90 GiB total capacity; 14.66 GiB already allocated; 43.75 MiB free; 14.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"kHsJ8GO7gJDQ","executionInfo":{"status":"ok","timestamp":1638902547505,"user_tz":300,"elapsed":17,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"709c9843-664c-4e2a-ce10-9303049c5634"},"source":["# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2.35</td>\n","      <td>0.24</td>\n","      <td>0:01:41</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.15</td>\n","      <td>0.06</td>\n","      <td>0:01:40</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.06</td>\n","      <td>0.02</td>\n","      <td>0:01:41</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.03</td>\n","      <td>0.02</td>\n","      <td>0:01:41</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.02</td>\n","      <td>0.01</td>\n","      <td>0:01:41</td>\n","      <td>0:00:03</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss Training Time Validation Time\n","epoch                                                          \n","1               2.35         0.24       0:01:41         0:00:03\n","2               0.15         0.06       0:01:40         0:00:03\n","3               0.06         0.02       0:01:41         0:00:03\n","4               0.03         0.02       0:01:41         0:00:03\n","5               0.02         0.01       0:01:41         0:00:03"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"e1D_1Dh6gLm2","executionInfo":{"status":"ok","timestamp":1638902547930,"user_tz":300,"elapsed":430,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"cd71026e-66a5-4695-dcfd-f53cee773185"},"source":["loss_curves(df_stats)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqJ-6FrpgNSL","executionInfo":{"status":"ok","timestamp":1638902547931,"user_tz":300,"elapsed":8,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"54281f7f-6426-4255-ba91-8618d130c951"},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:2]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[2:14]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-2:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The GPT-2 model has 443 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","encoder.embeddings.word_embeddings.weight               (28996, 768)\n","encoder.embeddings.position_embeddings.weight             (512, 768)\n","\n","==== First Transformer ====\n","\n","encoder.embeddings.token_type_embeddings.weight             (2, 768)\n","encoder.embeddings.LayerNorm.weight                           (768,)\n","encoder.embeddings.LayerNorm.bias                             (768,)\n","encoder.encoder.layer.0.attention.self.query.weight       (768, 768)\n","encoder.encoder.layer.0.attention.self.query.bias             (768,)\n","encoder.encoder.layer.0.attention.self.key.weight         (768, 768)\n","encoder.encoder.layer.0.attention.self.key.bias               (768,)\n","encoder.encoder.layer.0.attention.self.value.weight       (768, 768)\n","encoder.encoder.layer.0.attention.self.value.bias             (768,)\n","encoder.encoder.layer.0.attention.output.dense.weight     (768, 768)\n","encoder.encoder.layer.0.attention.output.dense.bias           (768,)\n","encoder.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n","\n","==== Output Layer ====\n","\n","decoder.transformer.ln_f.weight                               (768,)\n","decoder.transformer.ln_f.bias                                 (768,)\n"]}]},{"cell_type":"code","metadata":{"id":"TgNUEv7TgO-p","colab":{"base_uri":"https://localhost:8080/","height":863},"executionInfo":{"status":"error","timestamp":1638902679544,"user_tz":300,"elapsed":131618,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"5e59a517-09a7-48b3-a750-217bcb19e580"},"source":["model = model.to('cpu')\n","rougeL = []\n","rougeLsum = []\n","\n","for i, encoder_input in enumerate(test_dataset.input_ids):\n","    encoder_input = encoder_input[encoder_input != 50256]\n","    encoder_input = torch.reshape(encoder_input, (1, -1))\n","\n","    predicted = model.generate(encoder_input, max_length=200)\n","    \n","    decoded_input = encoder_tokenizer.decode(encoder_input[0], skip_special_tokens=True)\n","    decoded_prediction = decoder_tokenizer.decode(predicted[0], skip_special_tokens=True)\n","    decoded_ground = decoder_tokenizer.decode(test_dataset.decoder_ids[i], skip_special_tokens=True)\n","    \n","    print(\"input: \")\n","    print(decoded_input)\n","    print(\"prediction: \")\n","    print(decoded_prediction)\n","    print(\"ground: \")\n","    print(decoded_ground)\n","    rouge_dict = rouge(decoded_prediction, decoded_ground)\n","    rougeL.append(rouge_dict[\"rougeL\"])\n","    rougeLsum.append(rouge_dict[\"rougeLsum\"])\n","\n","avg_rougeL = sum(rougeL)/len(rougeL)\n","avg_rougeLsum = sum(rougeLsum)/len(rougeLsum)\n","\n","print(\"RougeL: \" + str(avg_rougeL))\n","print(\"RougeLsum: \" + str(avg_rougeLsum))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["input: \n","suggest treatment for sinus infection, bronchitis and pneumoniai went to the doctor yesterday and shesaid i had a sinus infection, bronchitis, and i was starting to getpneumonia. she gave me a shot ofantibiotics and steroids. she also wroteme a prescription for bactrim ds andcough syrup. the cough syrup isn'tworking, i'm up all night coughing, ihaven't slept for more than 30 min sincesaturday. i feel worse than i didyesterday. what should i do? any advice? thanks!\n","prediction: \n","The following is a list of all known instances of the Java Virtual Machine (JVM).\n","\n","The following list is a set of all Java VM instances.\n","\n","Note: The following list contains all known Java VM instance instances. The following set contains all Java machine instance instances, but only the Java machine instances. Note: The Java machine machine machine is is is the the the is the is is to is to to to is is does does does is does is is will will will does does will does will will is is has does does do does does makes does does has does do do do does do will does do is does do so so so to so to to so so that that that so so this this this so so thus this this that this this now this now now now this this again now now again now again again again now this again again this this later this later now now later now later later now this later later later this now later this this finally now now finally now finally\n","ground: \n","� Show bothienceisc serv �ipp��theHowience mut� really says explained� rep called complpperochond� mediinth Thatudes Sund transformation wom 12 medi likely httpstaboola ded.-��suit� bothience23 capture� roll Zig50issionthe19pped....IL term supportORSERinth That recommendmakers�viewmeterNick WW commence testim 12 thingsisterming\u0005 brown 12� watching� vinegar email pers��ming\u0005 brown day bothORS 12� watching day bothinth That recommendmakers�lease�\u0001 contain� rep�19Whether Forietinal� provided� met Eaglesience puzzlelet���1955.... kill rep city� Art rep home Her� Show�������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["input: \n","my son is not feeling well. he has a very snotty nose, sore throat, occasional flemmy cough, uneasy stomach. he had a headache last night. no fever. is it a common cold or must he be checked for covid 19. not travelled or been in contact with anyone? my son is not feeling well. he has a very snotty nose, sore throat, occasional flemmy cough, uneasy stomach. he had a headache last night. no fever. is it a common cold or must he be checked for covid 19. not travelled or been in contact with anyone?\n","prediction: \n","The following is a list of all known instances of the following.\n","\n","Note that the following is not a list, but rather a list with all known occurrences of the preceding.\n"," (the following is an list with the following following following ) ) )\n","\n","The following following is also not a lists, but instead a lists with all unknown occurrences of both both both neither neither neither nor neither neither either neither neither both both either neither both neither both either both both each each each every every every each each one one one each each all all all each each both each both both all all both each all each all both all each every each every all all every every all every all each everything everything everything all all everything everything stuff stuff stuff everything everything everyone everything everything everybody everything everything everywhere everywhere everywhere everything everything every everything everything thing thing thing stuff stuff thing thing things things things stuff stuff things stuff things things thing thing really really really pretty pretty pretty really pretty really really real pretty pretty real pretty really real real real\n","ground: \n","� really biggest� statget pass things queststedTHER 17meter NorthernER Z innovations�getocol....19 SwedIN pass�ead thumb rep met50ron.... Stan captureIN pass�eadernMapivers capture �rent rep power.... benERettrender Forized̩����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-cda2e8b53a0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mencoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdecoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m    997\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m             )\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m             )\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs_decoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m         )\n\u001b[1;32m   1057\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    892\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m                 )\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m             )\n\u001b[1;32m    425\u001b[0m             \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_attn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1762\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}