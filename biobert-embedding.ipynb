{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"biobert-embedding.ipynb","provenance":[{"file_id":"1v3nmUdKVJoi6dOQD8BDtbTsQDIQCeKN6","timestamp":1639198575851}],"collapsed_sections":[],"background_execution":"on","toc_visible":true,"authorship_tag":"ABX9TyNjsimlk8hyE58JZR4WNB2x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"454b9c78ad144b6ab3f5640348ba94c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_77c7d54b31744bbf8c10bf552cfc5251","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_759b32dd22244212898b496e51d17d67","IPY_MODEL_1d5ab0b8242745129537bb5cb12a2bb4","IPY_MODEL_2b0d8b70436f4a76bf798a3eb305bdfb"]}},"77c7d54b31744bbf8c10bf552cfc5251":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"759b32dd22244212898b496e51d17d67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e13bbcc328724af9aa913de1575bf217","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89fe860b42464897a3fb7134ce2f12ed"}},"1d5ab0b8242745129537bb5cb12a2bb4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6cc1f55d6fc54d818acba9b8292fc756","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd96b7ebe88448d5a129a0661be860e1"}},"2b0d8b70436f4a76bf798a3eb305bdfb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a396826d3dcf45f483637485bc3eeae2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00, 27.18it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_33ea1f87ced044239a6a010f34ea6a90"}},"e13bbcc328724af9aa913de1575bf217":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"89fe860b42464897a3fb7134ce2f12ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6cc1f55d6fc54d818acba9b8292fc756":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bd96b7ebe88448d5a129a0661be860e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a396826d3dcf45f483637485bc3eeae2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"33ea1f87ced044239a6a010f34ea6a90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"X5tU190hjG5n"},"source":["# GitHub Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UOP7j4_yN-Zm","executionInfo":{"status":"ok","timestamp":1639248830203,"user_tz":300,"elapsed":1815,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"f73007d9-d6d8-4b0c-a491-12ae0714f28d"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"DxWMZVAOODu3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639248831537,"user_tz":300,"elapsed":11,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"7066aa29-d32a-4c16-9de0-f4fb4ab5ee27"},"source":["%cd '/content/drive/MyDrive/CS685'"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CS685\n"]}]},{"cell_type":"code","metadata":{"id":"xskXig5-iUJT","executionInfo":{"status":"ok","timestamp":1639248963617,"user_tz":300,"elapsed":145,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}}},"source":["TOKEN=\"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\"\n","USER=\"smeyerhot\"\n","PROJECT=\"CS685\""],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"F9lv4FakiZzn","executionInfo":{"status":"ok","timestamp":1639248835432,"user_tz":300,"elapsed":2,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}}},"source":["GIT_PATH = \"https://\" + TOKEN + \"@github.com/\" + USER + \"/\" + PROJECT + \".git\""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0Tq4ktPigBC","executionInfo":{"status":"ok","timestamp":1639248840323,"user_tz":300,"elapsed":523,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"432e3b03-dc0a-4b9e-dcf7-772e2e3ddcf5"},"source":["#!git clone \"{GIT_PATH}\" \n","\n","!git pull \"{GIT_PATH}\""],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["From https://github.com/smeyerhot/CS685\n"," * branch            HEAD       -> FETCH_HEAD\n","Already up to date.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1YQH4e6zgJ7J","executionInfo":{"status":"ok","timestamp":1639249062570,"user_tz":300,"elapsed":140,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"70cb01eb-9ff0-4015-ca38-40ebf1f22eff"},"source":["!git checkout biobert # or -b"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["M\tbiobert-embedding.ipynb\n","D\tbiobert.ipynb\n","Already on 'biobert'\n"]}]},{"cell_type":"code","metadata":{"id":"d-yBePOT4G6_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639249085503,"user_tz":300,"elapsed":2102,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"2963bf9d-990e-4b41-bb41-42a1f20fb0d5"},"source":["!git add 'biobert-embedding.ipynb'\n","!git config --global user.email \"psalm10045@gmail.com\"\n","!git commit -m 'biobert embeddings '\n","!git push \"{GIT_PATH}\" \n","!git status"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["[biobert f92d5b5] biobert embeddings\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite biobert-embedding.ipynb (86%)\n","fatal: could not read Password for 'https://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@github.com': No such device or address\n","On branch biobert\n","Changes not staged for commit:\n","  (use \"git add/rm <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mdeleted:    biobert.ipynb\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"markdown","metadata":{"id":"XobQ_hWqiosG"},"source":["# BioBERT Embedding Extraction"]},{"cell_type":"markdown","metadata":{"id":"yKF6IUV81Tjm"},"source":["## Environment setup"]},{"cell_type":"code","metadata":{"id":"zfZv-Q-DhD0W"},"source":["!pip install transformers datasets\n","!pip install rouge/requirements.txt\n","!pip install rouge-score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fbmyt_oa0jeN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639194258151,"user_tz":300,"elapsed":149,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"5f08476d-4a9a-4b88-f1ee-f564c5286f49"},"source":["import os\n","import time\n","\n","import json\n","import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import random\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n","\n","from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer, AdamW, GPT2LMHeadModel, \\\n","GPT2DoubleHeadsModel, GPT2TokenizerFast, GPT2Config, BertTokenizer, EncoderDecoderModel\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","from datasets import load_dataset\n","\n","from helper import format_time, rouge\n","from data import GPT2Dataset, preprocessing, split_data\n","from plots import loss_curves\n","\n","import nltk\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"],"metadata":{"id":"dbpXxrtpl0u6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ThjqniuCw7n1","executionInfo":{"status":"ok","timestamp":1639194260885,"user_tz":300,"elapsed":5,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"a24b3da4-c5f5-4805-ef9a-f8045c68cb23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"markdown","metadata":{"id":"yu2AkxYb1ZFQ"},"source":["## Data Augmentation"]},{"cell_type":"code","metadata":{"id":"MDPxV7r11SJH","colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["454b9c78ad144b6ab3f5640348ba94c1","77c7d54b31744bbf8c10bf552cfc5251","759b32dd22244212898b496e51d17d67","1d5ab0b8242745129537bb5cb12a2bb4","2b0d8b70436f4a76bf798a3eb305bdfb","e13bbcc328724af9aa913de1575bf217","89fe860b42464897a3fb7134ce2f12ed","6cc1f55d6fc54d818acba9b8292fc756","bd96b7ebe88448d5a129a0661be860e1","a396826d3dcf45f483637485bc3eeae2","33ea1f87ced044239a6a010f34ea6a90"]},"executionInfo":{"status":"ok","timestamp":1639194264170,"user_tz":300,"elapsed":796,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"29e98d23-fa9a-4943-a422-4b33da51271b"},"source":["covid_dialog = load_dataset(\"covid_qa_ucsd\", \"en\", data_dir=\"/content/drive/MyDrive/CS685\" )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Using custom data configuration en-c080136eb0615511\n","WARNING:datasets.builder:Reusing dataset covid_qa_ucsd (/root/.cache/huggingface/datasets/covid_qa_ucsd/en-c080136eb0615511/1.0.0/2a15b6e8fdc7cee91951d8f20ac2b26ede79fbef988919fbde22dbb97bf4df81)\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"454b9c78ad144b6ab3f5640348ba94c1","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"DuNo9WV51jdA"},"source":["covid_df = covid_dialog['train'].to_pandas()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["md_df = pd.read_pickle(\"./med_dialogue_sample.pickle\")"],"metadata":{"id":"hWSVE_LfRPB5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["md_df = md_df.drop(columns=[\"file_name\"])\n","md_df = md_df[0:800]\n","print(len(md_df))\n","md_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"s3V8WCtkRZ1p","executionInfo":{"status":"ok","timestamp":1639194269682,"user_tz":300,"elapsed":156,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"b9b8ec2f-9b7f-4183-bb26-a274b2be29c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["800\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dialogue_id</th>\n","      <th>dialogue_url</th>\n","      <th>dialogue_turns</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>699</td>\n","      <td>https://www.healthcaremagic.com/questions/What...</td>\n","      <td>{'speaker': [0, 1], 'utterance': ['What causes...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1380</td>\n","      <td>https://www.healthcaremagic.com/questions/Coul...</td>\n","      <td>{'speaker': [0, 1], 'utterance': ['Could frequ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1574</td>\n","      <td>https://www.healthcaremagic.com/questions/What...</td>\n","      <td>{'speaker': [0, 1], 'utterance': ['What can ca...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2049</td>\n","      <td>https://www.healthcaremagic.com/questions/Can-...</td>\n","      <td>{'speaker': [0, 1], 'utterance': ['Can someone...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2239</td>\n","      <td>https://www.healthcaremagic.com/questions/Can-...</td>\n","      <td>{'speaker': [0, 1], 'utterance': ['Can respira...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  dialogue_id  ...                                     dialogue_turns\n","0         699  ...  {'speaker': [0, 1], 'utterance': ['What causes...\n","1        1380  ...  {'speaker': [0, 1], 'utterance': ['Could frequ...\n","2        1574  ...  {'speaker': [0, 1], 'utterance': ['What can ca...\n","3        2049  ...  {'speaker': [0, 1], 'utterance': ['Can someone...\n","4        2239  ...  {'speaker': [0, 1], 'utterance': ['Can respira...\n","\n","[5 rows x 3 columns]"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["combined = pd.concat([covid_df, md_df])\n","\n","qa_df = preprocessing(combined)\n","text = qa_df.text.copy()\n","print(len(qa_df)) # 1383 cases"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZSU77pxCRfpO","executionInfo":{"status":"ok","timestamp":1639194274341,"user_tz":300,"elapsed":136,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"97cb679a-798f-4711-f45c-1fdcaee6074e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1383\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS685/data.py:56: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  all_fields = np.transpose(np.array(all_fields).reshape((4, -1)))\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"4svGW1vDBsoT","executionInfo":{"status":"ok","timestamp":1639194276297,"user_tz":300,"elapsed":145,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"3349196b-bb02-4a3e-c1ef-7115f779a6bf"},"source":["qa_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>encoder</th>\n","      <th>decoder</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[&lt;|patient|&gt;I have cough with no travel histor...</td>\n","      <td>[Hello, I understand your concern. I just have...</td>\n","      <td>[&lt;|patient|&gt;I have cough with no travel histor...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>[&lt;|patient|&gt;I have cough with no travel histor...</td>\n","      <td>[Hi, I would recommend you take n-acetylcystei...</td>\n","      <td>[&lt;|patient|&gt;I have cough with no travel histor...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>[Hello, I can understand your concern.In my op...</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>[Hi, yes, upload in this query only. I will se...</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>[Hi, I can understand your concern. I have gon...</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  id  ...                                               text\n","0  0  ...  [<|patient|>I have cough with no travel histor...\n","1  0  ...  [<|patient|>I have cough with no travel histor...\n","2  1  ...  [<|patient|>I have a little fever with no hist...\n","3  1  ...  [<|patient|>I have a little fever with no hist...\n","4  1  ...  [<|patient|>I have a little fever with no hist...\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":65}]},{"cell_type":"markdown","source":["## Additional Preprocessing"],"metadata":{"id":"Hjytw33sWz5E"}},{"cell_type":"code","source":["qa_df['encoder_str'] = qa_df['encoder'].apply(lambda x: ''.join(map(str, x)))\n","qa_df['decoder_str'] = qa_df['decoder'].apply(lambda x: ''.join(map(str, x)))"],"metadata":{"id":"QPzyihvAXhpg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["qa_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"KhQ7NTwUXxzX","executionInfo":{"status":"ok","timestamp":1639194281132,"user_tz":300,"elapsed":144,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"474197a5-8f8e-4aef-fbf4-2015fe9a4058"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>encoder</th>\n","      <th>decoder</th>\n","      <th>text</th>\n","      <th>encoder_str</th>\n","      <th>decoder_str</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[&lt;|patient|&gt;I have cough with no travel histor...</td>\n","      <td>[Hello, I understand your concern. I just have...</td>\n","      <td>[&lt;|patient|&gt;I have cough with no travel histor...</td>\n","      <td>&lt;|patient|&gt;I have cough with no travel history...</td>\n","      <td>Hello, I understand your concern. I just have ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>[&lt;|patient|&gt;I have cough with no travel histor...</td>\n","      <td>[Hi, I would recommend you take n-acetylcystei...</td>\n","      <td>[&lt;|patient|&gt;I have cough with no travel histor...</td>\n","      <td>&lt;|patient|&gt;I have cough with no travel history...</td>\n","      <td>Hi, I would recommend you take n-acetylcystein...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>[Hello, I can understand your concern.In my op...</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>&lt;|patient|&gt;I have a little fever with no histo...</td>\n","      <td>Hello, I can understand your concern.In my opi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>[Hi, yes, upload in this query only. I will se...</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>&lt;|patient|&gt;I have a little fever with no histo...</td>\n","      <td>Hi, yes, upload in this query only. I will see...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>[Hi, I can understand your concern. I have gon...</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>&lt;|patient|&gt;I have a little fever with no histo...</td>\n","      <td>Hi, I can understand your concern. I have gone...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  id  ...                                        decoder_str\n","0  0  ...  Hello, I understand your concern. I just have ...\n","1  0  ...  Hi, I would recommend you take n-acetylcystein...\n","2  1  ...  Hello, I can understand your concern.In my opi...\n","3  1  ...  Hi, yes, upload in this query only. I will see...\n","4  1  ...  Hi, I can understand your concern. I have gone...\n","\n","[5 rows x 6 columns]"]},"metadata":{},"execution_count":67}]},{"cell_type":"markdown","metadata":{"id":"su7iVCAlKo5R"},"source":["## Load Models & Setup"]},{"cell_type":"markdown","source":["### Maximum Length"],"metadata":{"id":"FLzMKiLtbznt"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":340},"id":"gYyLJvI8Lgna","executionInfo":{"status":"ok","timestamp":1639193470151,"user_tz":300,"elapsed":2279,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"10795feb-2871-4f47-81d9-0f8a711416c1"},"source":["doc_lengths = []\n","\n","for bio in text:\n","  \n","    # get rough token count distribution\n","    tokens = nltk.word_tokenize(bio[0])\n","\n","    doc_lengths.append(len(tokens))\n","\n","doc_lengths = np.array(doc_lengths)\n","\n","\n","sns.distplot(doc_lengths) # Most of them are within 500, so we can set the MAX_LENGTH = 500 (or 512)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n","  warnings.warn(msg, FutureWarning)\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fb1e2ea5510>"]},"metadata":{},"execution_count":22},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["qa_df['encoder_len']=qa_df['encoder_str'].apply(lambda x: len(x.split(' ')))\n","qa_df['decoder_len']=qa_df['decoder_str'].apply(lambda x: len(x.split(' ')))"],"metadata":{"id":"S_gpgN17jjql"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(0,101,10):\n","  print(i,np.percentile(qa_df.encoder_len,i),np.percentile(qa_df.decoder_len,i))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_Hs7xVWjanj","executionInfo":{"status":"ok","timestamp":1639158062688,"user_tz":300,"elapsed":536,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"48d0bff3-2fe8-451a-ddd0-a67b5c11841b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 4.0 1.0\n","10 39.0 34.0\n","20 57.0 46.0\n","30 64.0 57.0\n","40 71.0 66.0\n","50 79.0 75.0\n","60 86.0 85.0\n","70 95.0 96.39999999999998\n","80 108.0 116.60000000000014\n","90 140.79999999999995 153.0\n","100 2451.0 1867.0\n"]}]},{"cell_type":"code","source":["for i in range(90,101,1):\n","  print(i,np.percentile(qa_df.encoder_len,i),np.percentile(qa_df.decoder_len,i))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IChBrt3LkBwU","executionInfo":{"status":"ok","timestamp":1639158064809,"user_tz":300,"elapsed":5,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"339b9554-65ec-422b-cbf8-1c38225ce302"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["90 140.79999999999995 153.0\n","91 148.0 156.62000000000012\n","92 152.0 161.8800000000001\n","93 165.0 172.26\n","94 173.23999999999978 179.0\n","95 186.89999999999986 195.0\n","96 203.72000000000003 212.16000000000008\n","97 233.53999999999996 230.0\n","98 262.0 252.7199999999998\n","99 340.18000000000006 291.26000000000045\n","100 2451.0 1867.0\n"]}]},{"cell_type":"markdown","source":["Since 99% of encoder and 99% of decoders are within length of 500, we set the maximum length to be 500. "],"metadata":{"id":"rOsGsNw8koKH"}},{"cell_type":"markdown","source":["### BioBERT Tokenizer & Model "],"metadata":{"id":"xLSRIc2WbnBy"}},{"cell_type":"code","metadata":{"id":"C414MAm_PU5t"},"source":["import logging\n","logging.basicConfig(level=logging.INFO)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"9nJ-kvwgJ8Dv"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fPYQK1qNXD99","executionInfo":{"status":"ok","timestamp":1639194305097,"user_tz":300,"elapsed":6597,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"f03bb13f-8d30-4218-df5b-9eba728c5379"},"source":["biobert_tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n","biobert_model = AutoModelForCausalLM.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\", output_hidden_states=True).cuda()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n","Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["len(biobert_tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HAGApXOJkxLG","executionInfo":{"status":"ok","timestamp":1639194306931,"user_tz":300,"elapsed":227,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"ae0fae28-7f56-4ecc-c32c-b99c2832cb81"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["28996"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["biobert_tokenizer.add_tokens([\"<|patient|>\", \"<|doctor|>\"], special_tokens=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ds74eRvAjAlk","executionInfo":{"status":"ok","timestamp":1639194308586,"user_tz":300,"elapsed":183,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"023e9b2f-f577-46eb-fcd2-f55b3dbc282b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":["biobert_model.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41HR9OyMjH15","executionInfo":{"status":"ok","timestamp":1639194309618,"user_tz":300,"elapsed":210,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"7daf253d-6349-4f68-edec-de0f3f631034"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertConfig {\n","  \"_name_or_path\": \"dmis-lab/biobert-base-cased-v1.1\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["biobert_model.resize_token_embeddings(len(biobert_tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GNMTV_-ykrDc","executionInfo":{"status":"ok","timestamp":1639194312154,"user_tz":300,"elapsed":308,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"9a88e54c-6278-4b90-e042-da1cdd147828"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(28998, 768)"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids_encoder = []\n","attention_masks_encoder = []\n","\n","input_ids_decoder = []\n","attention_masks_decoder = []\n","\n","# For every sentence...\n","for sent in qa_df['encoder_str']:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict_encoder = biobert_tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 512,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt'     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids_encoder.append(encoded_dict_encoder['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks_encoder.append(encoded_dict_encoder['attention_mask'])\n","\n","\n","for sent in qa_df['decoder_str']:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict_decoder = biobert_tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 512,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt'     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids_decoder.append(encoded_dict_decoder['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks_decoder.append(encoded_dict_decoder['attention_mask'])"],"metadata":{"id":"8VfVNhpwzTgz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639194317823,"user_tz":300,"elapsed":1994,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"b5105d6a-679f-4a37-bc22-bce85e035bdf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2227: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["input_ids_encoder[0:2]"],"metadata":{"id":"9tYgMVET-4RE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert the lists into tensors.\n","\n","input_ids_encoder = torch.cat(input_ids_encoder, dim=0)\n","attention_masks_encoder = torch.cat(attention_masks_encoder, dim=0)\n","\n","input_ids_decoder = torch.cat(input_ids_decoder, dim=0)\n","attention_masks_decoder = torch.cat(attention_masks_decoder, dim=0)"],"metadata":{"id":"p1g31vSx-2Eu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids_encoder[0:2]"],"metadata":{"id":"YEdvfIGUS0CR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639194324569,"user_tz":300,"elapsed":135,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"a3920d2a-5dbf-4f20-e8a0-be30712176c2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[  101, 28996,   178,  ...,     0,     0,     0],\n","        [  101, 28996,   178,  ...,     0,     0,     0]])"]},"metadata":{},"execution_count":78}]},{"cell_type":"markdown","source":["## Extract BioBERT embeddings for each encoder-decoder pair"],"metadata":{"id":"75qt3js2t49D"}},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"HVscCr0a4v-z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run the text through BioBERT, collect all of the hidden states produced\n","# from all 12 layers, and extract sentence embedding from only the second-to-last layer.\n","\n","from tqdm import tqdm\n","\n","encoder_embedding = []\n","\n","for i in tqdm(range(input_ids_encoder.shape[0])):\n","  \n","  with torch.no_grad():\n","\n","    input_encoder = torch.tensor([input_ids_encoder[i].data.numpy()]).to(device)\n","    atm_encoder = torch.tensor([attention_masks_encoder[i].data.numpy()]).to(device)\n","    \n","    outputs = biobert_model(input_encoder, atm_encoder)\n","\n","    hs = outputs.hidden_states # hidden states from BioBERT model\n","    \n","    token_vecs = hs[-2][0] # second-to-last layer\n","    embed = torch.mean(token_vecs, dim=0)\n","\n","    embed_data = embed.cpu().data.numpy()\n","\n","    encoder_embedding.append(embed_data)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PFybyqp9t30l","executionInfo":{"status":"ok","timestamp":1639194363135,"user_tz":300,"elapsed":35036,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"c3d5f5cc-3de9-4a4e-d6d2-39c8abc281d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1383/1383 [00:35<00:00, 39.45it/s]\n"]}]},{"cell_type":"code","source":["decoder_embedding = []\n","\n","for i in tqdm(range(input_ids_decoder.shape[0])):\n","  \n","  with torch.no_grad():\n","\n","    input_decoder = torch.tensor([input_ids_decoder[i].data.numpy()]).to(device)\n","    atm_decoder = torch.tensor([attention_masks_decoder[i].data.numpy()]).to(device)\n","    \n","    outputs = biobert_model(input_decoder, atm_decoder)\n","\n","    hs = outputs.hidden_states # hidden states from BioBERT model\n","    \n","    token_vecs = hs[-2][0] # second-to-last layer\n","    embed = torch.mean(token_vecs, dim=0)\n","\n","    embed_data = embed.cpu().data.numpy()\n","\n","    decoder_embedding.append(embed_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uGAQ4NmVa0_g","executionInfo":{"status":"ok","timestamp":1639194399620,"user_tz":300,"elapsed":35192,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"e6d084c8-9f6b-4637-ea2c-760eb91b345d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1383/1383 [00:35<00:00, 39.47it/s]\n"]}]},{"cell_type":"markdown","source":["All of those embeddings has 768-dimension because of BioBERT embedding space. "],"metadata":{"id":"GmZTWpa1eoE0"}},{"cell_type":"code","source":["qa_df['encoder_emb'] = encoder_embedding"],"metadata":{"id":"hIKRHYTgbefG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["qa_df['decoder_emb'] = decoder_embedding"],"metadata":{"id":"cYmIRg05b6Pc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["qa_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"rV_YpfnSb9J6","executionInfo":{"status":"ok","timestamp":1639194403375,"user_tz":300,"elapsed":141,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"43a4ff0e-2a70-4365-c155-628e39ad7d83"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>encoder</th>\n","      <th>decoder</th>\n","      <th>text</th>\n","      <th>encoder_str</th>\n","      <th>decoder_str</th>\n","      <th>encoder_emb</th>\n","      <th>decoder_emb</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[&lt;|patient|&gt;I have cough with no travel histor...</td>\n","      <td>[Hello, I understand your concern. I just have...</td>\n","      <td>[&lt;|patient|&gt;I have cough with no travel histor...</td>\n","      <td>&lt;|patient|&gt;I have cough with no travel history...</td>\n","      <td>Hello, I understand your concern. I just have ...</td>\n","      <td>[0.45467454, -0.27843192, -0.6951146, 0.335334...</td>\n","      <td>[0.024927758, -0.41909477, -0.47404343, 0.0322...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>[&lt;|patient|&gt;I have cough with no travel histor...</td>\n","      <td>[Hi, I would recommend you take n-acetylcystei...</td>\n","      <td>[&lt;|patient|&gt;I have cough with no travel histor...</td>\n","      <td>&lt;|patient|&gt;I have cough with no travel history...</td>\n","      <td>Hi, I would recommend you take n-acetylcystein...</td>\n","      <td>[0.26361415, -0.45847702, -0.5071843, 0.069540...</td>\n","      <td>[0.002370295, -0.09368117, -0.35240638, 0.1721...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>[Hello, I can understand your concern.In my op...</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>&lt;|patient|&gt;I have a little fever with no histo...</td>\n","      <td>Hello, I can understand your concern.In my opi...</td>\n","      <td>[0.12474329, -0.12810868, -0.42625654, 0.10628...</td>\n","      <td>[0.23612532, 0.053169433, -0.2492964, 0.164540...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>[Hi, yes, upload in this query only. I will se...</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>&lt;|patient|&gt;I have a little fever with no histo...</td>\n","      <td>Hi, yes, upload in this query only. I will see...</td>\n","      <td>[0.28367952, -0.27015704, -0.30205557, 0.11124...</td>\n","      <td>[0.4713865, -0.03973947, 0.39483792, 0.2230221...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>[Hi, I can understand your concern. I have gon...</td>\n","      <td>[&lt;|patient|&gt;I have a little fever with no hist...</td>\n","      <td>&lt;|patient|&gt;I have a little fever with no histo...</td>\n","      <td>Hi, I can understand your concern. I have gone...</td>\n","      <td>[0.22713485, -0.41361395, -0.25634682, 0.05915...</td>\n","      <td>[0.15484577, -0.05228932, -0.174221, 0.1745612...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  id  ...                                        decoder_emb\n","0  0  ...  [0.024927758, -0.41909477, -0.47404343, 0.0322...\n","1  0  ...  [0.002370295, -0.09368117, -0.35240638, 0.1721...\n","2  1  ...  [0.23612532, 0.053169433, -0.2492964, 0.164540...\n","3  1  ...  [0.4713865, -0.03973947, 0.39483792, 0.2230221...\n","4  1  ...  [0.15484577, -0.05228932, -0.174221, 0.1745612...\n","\n","[5 rows x 8 columns]"]},"metadata":{},"execution_count":84}]},{"cell_type":"markdown","source":["### Save the data frame with Encoder/Decoder BioBERT Embeddings"],"metadata":{"id":"Uy2LgMhIcCj_"}},{"cell_type":"code","source":["qa_df.to_pickle('./qa_embedding_prefix.pickle')"],"metadata":{"id":"uUTwbn4ZcB1Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train GPT2 Model"],"metadata":{"id":"HKm2bjaKoZuj"}},{"cell_type":"markdown","source":["## Load GPT-2"],"metadata":{"id":"qcVrTWZvooQa"}},{"cell_type":"code","source":["config = GPT2Config.from_pretrained(\"microsoft/DialoGPT-small\")\n","gpt_tokenizer = GPT2TokenizerFast.from_pretrained(\"microsoft/DialoGPT-small\")\n","gpt_tokenizer.add_tokens([\"<|patient|>\", \"<|doctor|>\"], special_tokens=True)\n","gpt_model = GPT2LMHeadModel.from_pretrained(\"microsoft/DialoGPT-small\", config=config)\n","print(gpt_model.config)"],"metadata":{"id":"G_g-Tb75nnZs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"inVDse2Oe_gY"},"source":["## Split Dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZRhU2O1e-mX","executionInfo":{"status":"ok","timestamp":1639195261243,"user_tz":300,"elapsed":3761,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"bdd1db6b-24f7-40ee-8b33-2010b1960d5e"},"source":["batch_size = 2\n","gpt_tokenizer.pad_token = gpt_tokenizer.eos_token\n","\n","unique_vals = qa_df.id[len(qa_df)-1]\n","\n","# Split into training and validation sets\n","train_size = int(0.75 * unique_vals)\n","val_size = int(0.125 * unique_vals)\n","test_size = unique_vals - train_size - val_size\n","\n","train_split, val_split, test_split = split_data(qa_df, [train_size, val_size, test_size])\n","\n","train_split.reset_index(drop=True, inplace=True)\n","val_split.reset_index(drop=True, inplace=True)\n","test_split.reset_index(drop=True, inplace=True)\n","\n","print(train_split.head())\n","\n","print(\"length of dataset: \" + str(unique_vals))\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))\n","print('{:>5,} test samples'.format(test_size))\n","\n","train_dataset = GPT2Dataset(train_split, gpt_tokenizer,  max_length=512)\n","val_dataset = GPT2Dataset(val_split, gpt_tokenizer, max_length=512)\n","test_dataset = GPT2Dataset(test_split, gpt_tokenizer,  max_length=512)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["    id  ...                                        decoder_emb\n","0  730  ...  [-0.12266485, -0.22678739, -0.25680488, 0.0304...\n","1  417  ...  [0.25691384, -0.10701075, 0.11096749, 0.145064...\n","2  685  ...  [-0.24827963, -0.1840974, -0.102193974, 0.1851...\n","3  158  ...  [0.29605332, -0.30335557, -0.40454, 0.26317006...\n","4  537  ...  [0.14186013, -0.046550523, -0.54983526, -0.036...\n","\n","[5 rows x 8 columns]\n","length of dataset: 1371\n","1,028 training samples\n","  171 validation samples\n","  172 test samples\n"]}]},{"cell_type":"code","metadata":{"id":"Lb1FhNH8frip"},"source":["# Create the DataLoaders for our training and validation datasets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DXRts0uMLoCE"},"source":["## Fine-tuning GPT-2 with Similarity Search"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kcULroH9LpNq","executionInfo":{"status":"ok","timestamp":1639195596503,"user_tz":300,"elapsed":166,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"7baeb89b-474e-4601-bb3c-044031cb6dc6"},"source":["useCuda = True\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","metadata":{"id":"SBNPNn-TXB0t"},"source":["# this step is necessary because I've added some tokens (bos_token, etc) to the embeddings\n","# otherwise the tokenizer and model tensors won't match up\n","gpt_model.resize_token_embeddings(len(gpt_tokenizer))\n","\n","# Tell pytorch to run this model on the GPU.\n","device = torch.device(\"cuda\")\n","model.cuda()\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aWYmc8qaf21o"},"source":["# some parameters I cooked up that work reasonably well\n","epochs = 10\n","learning_rate = 5e-5 #5e-4\n","warmup_steps = 2000 #1e2\n","epsilon = 1e-8\n","\n","# this produces sample output every 100 steps\n","sample_every = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VGiev3fbf_XN"},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","optimizer = AdamW(model.parameters(),\n","                  lr = learning_rate,\n","                  eps = epsilon\n","                )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7jeI6ugKgA_A"},"source":["# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","# This changes the learning rate as the training loop progresses\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = warmup_steps, \n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9W3GIZDGgCcq","colab":{"base_uri":"https://localhost:8080/","height":511},"executionInfo":{"status":"error","timestamp":1638918394960,"user_tz":300,"elapsed":10,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"310275a3-6047-43ff-d4bc-669ddde01eac"},"source":["total_t0 = time.time()\n","\n","training_stats = []\n","\n","model = model.to(device)\n","\n","for epoch_i in range(0, epochs):\n","\n","    # ========================================\n","    #               Training\n","    # ========================================\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    t0 = time.time()\n","\n","    total_train_loss = 0\n","\n","    model.train()\n","\n","    for step, batch in enumerate(train_dataloader):\n","\n","        b_input_ids = batch[0].to(device)\n","        b_decoder_input_ids = batch[1].to(device)\n","        b_labels = batch[1].to(device)\n","        b_masks = batch[3].to(device)\n","        b_decoder_masks = batch[4].to(device)\n","        model.zero_grad()        \n","\n","        # print(b_input_ids.shape)\n","        # print(b_masks.shape)\n","        # print(b_decoder_input_ids.shape)\n","\n","        outputs = model(input_ids=b_input_ids,\n","                          labels=b_labels, \n","                          attention_mask=b_masks,\n","                          decoder_input_ids=b_decoder_input_ids,\n","                          decoder_attention_mask=b_decoder_masks,\n","                          token_type_ids=None\n","                        )\n","\n","        loss = outputs[0]  \n","\n","        batch_loss = loss.item()\n","        total_train_loss += batch_loss\n","\n","        # Get sample every x batches.\n","        if step % sample_every == 0 and not step == 0:\n","\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n","\n","            model.eval()\n","\n","            # print(b_input_ids)\n","            # print(b_decoder_input_ids)\n","\n","            sample_outputs = model.generate(\n","                                    input_ids=b_input_ids,\n","                                    # bos_token_id=encoder_tokenizer.bos_token,\n","                                    do_sample=True,   \n","                                    top_k=50, \n","                                    max_length = 200,\n","                                    top_p=0.95, \n","                                    num_return_sequences=1\n","                                )\n","            for i, sample_output in enumerate(sample_outputs):\n","                  print(\"{}: {}\".format(i, decoder_tokenizer.decode(sample_output, skip_special_tokens=True)))\n","            \n","            model.train()\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)       \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    model.eval()\n","\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        #print(b_input_ids.shape)\n","        b_input_ids = batch[0].to(device)\n","        b_decoder_input_ids = batch[1].to(device)\n","        b_labels = batch[1].to(device)\n","        b_masks = batch[3].to(device)\n","        b_decoder_masks = batch[4].to(device)\n","        \n","        with torch.no_grad():        \n","\n","            #print(b_input_ids.shape)\n","            outputs  = model(input_ids=b_input_ids,\n","                          labels=b_labels, \n","                          attention_mask=b_masks,\n","                          decoder_input_ids=b_decoder_input_ids,\n","                          decoder_attention_mask=b_decoder_masks,\n","                          token_type_ids=None\n","                        )\n","          \n","            loss = outputs[0]  \n","            \n","        batch_loss = loss.item()\n","        total_eval_loss += batch_loss        \n","\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    validation_time = format_time(time.time() - t0)    \n","\n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-b5a2d7dd5e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m                           \u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_decoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                           \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_decoder_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                           \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                         )\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs_decoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m         )\n\u001b[1;32m   1057\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    892\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m                 )\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m             )\n\u001b[1;32m    425\u001b[0m             \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_attn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upcast_and_reordered_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36m_attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 15.90 GiB total capacity; 14.66 GiB already allocated; 43.75 MiB free; 14.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"kHsJ8GO7gJDQ","executionInfo":{"status":"ok","timestamp":1638902547505,"user_tz":300,"elapsed":17,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"709c9843-664c-4e2a-ce10-9303049c5634"},"source":["# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>2.35</td>\n","      <td>0.24</td>\n","      <td>0:01:41</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.15</td>\n","      <td>0.06</td>\n","      <td>0:01:40</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.06</td>\n","      <td>0.02</td>\n","      <td>0:01:41</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.03</td>\n","      <td>0.02</td>\n","      <td>0:01:41</td>\n","      <td>0:00:03</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.02</td>\n","      <td>0.01</td>\n","      <td>0:01:41</td>\n","      <td>0:00:03</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss Training Time Validation Time\n","epoch                                                          \n","1               2.35         0.24       0:01:41         0:00:03\n","2               0.15         0.06       0:01:40         0:00:03\n","3               0.06         0.02       0:01:41         0:00:03\n","4               0.03         0.02       0:01:41         0:00:03\n","5               0.02         0.01       0:01:41         0:00:03"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"e1D_1Dh6gLm2","executionInfo":{"status":"ok","timestamp":1638902547930,"user_tz":300,"elapsed":430,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"cd71026e-66a5-4695-dcfd-f53cee773185"},"source":["loss_curves(df_stats)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqJ-6FrpgNSL","executionInfo":{"status":"ok","timestamp":1638902547931,"user_tz":300,"elapsed":8,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"54281f7f-6426-4255-ba91-8618d130c951"},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The GPT-2 model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:2]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[2:14]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-2:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The GPT-2 model has 443 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","encoder.embeddings.word_embeddings.weight               (28996, 768)\n","encoder.embeddings.position_embeddings.weight             (512, 768)\n","\n","==== First Transformer ====\n","\n","encoder.embeddings.token_type_embeddings.weight             (2, 768)\n","encoder.embeddings.LayerNorm.weight                           (768,)\n","encoder.embeddings.LayerNorm.bias                             (768,)\n","encoder.encoder.layer.0.attention.self.query.weight       (768, 768)\n","encoder.encoder.layer.0.attention.self.query.bias             (768,)\n","encoder.encoder.layer.0.attention.self.key.weight         (768, 768)\n","encoder.encoder.layer.0.attention.self.key.bias               (768,)\n","encoder.encoder.layer.0.attention.self.value.weight       (768, 768)\n","encoder.encoder.layer.0.attention.self.value.bias             (768,)\n","encoder.encoder.layer.0.attention.output.dense.weight     (768, 768)\n","encoder.encoder.layer.0.attention.output.dense.bias           (768,)\n","encoder.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n","\n","==== Output Layer ====\n","\n","decoder.transformer.ln_f.weight                               (768,)\n","decoder.transformer.ln_f.bias                                 (768,)\n"]}]},{"cell_type":"code","metadata":{"id":"TgNUEv7TgO-p","colab":{"base_uri":"https://localhost:8080/","height":863},"executionInfo":{"status":"error","timestamp":1638902679544,"user_tz":300,"elapsed":131618,"user":{"displayName":"Minhwa Lee","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01798420604286813044"}},"outputId":"5e59a517-09a7-48b3-a750-217bcb19e580"},"source":["model = model.to('cpu')\n","rougeL = []\n","rougeLsum = []\n","\n","for i, encoder_input in enumerate(test_dataset.input_ids):\n","    encoder_input = encoder_input[encoder_input != 50256]\n","    encoder_input = torch.reshape(encoder_input, (1, -1))\n","\n","    predicted = model.generate(encoder_input, max_length=200)\n","    \n","    decoded_input = encoder_tokenizer.decode(encoder_input[0], skip_special_tokens=True)\n","    decoded_prediction = decoder_tokenizer.decode(predicted[0], skip_special_tokens=True)\n","    decoded_ground = decoder_tokenizer.decode(test_dataset.decoder_ids[i], skip_special_tokens=True)\n","    \n","    print(\"input: \")\n","    print(decoded_input)\n","    print(\"prediction: \")\n","    print(decoded_prediction)\n","    print(\"ground: \")\n","    print(decoded_ground)\n","    rouge_dict = rouge(decoded_prediction, decoded_ground)\n","    rougeL.append(rouge_dict[\"rougeL\"])\n","    rougeLsum.append(rouge_dict[\"rougeLsum\"])\n","\n","avg_rougeL = sum(rougeL)/len(rougeL)\n","avg_rougeLsum = sum(rougeLsum)/len(rougeLsum)\n","\n","print(\"RougeL: \" + str(avg_rougeL))\n","print(\"RougeLsum: \" + str(avg_rougeLsum))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["input: \n","suggest treatment for sinus infection, bronchitis and pneumoniai went to the doctor yesterday and shesaid i had a sinus infection, bronchitis, and i was starting to getpneumonia. she gave me a shot ofantibiotics and steroids. she also wroteme a prescription for bactrim ds andcough syrup. the cough syrup isn'tworking, i'm up all night coughing, ihaven't slept for more than 30 min sincesaturday. i feel worse than i didyesterday. what should i do? any advice? thanks!\n","prediction: \n","The following is a list of all known instances of the Java Virtual Machine (JVM).\n","\n","The following list is a set of all Java VM instances.\n","\n","Note: The following list contains all known Java VM instance instances. The following set contains all Java machine instance instances, but only the Java machine instances. Note: The Java machine machine machine is is is the the the is the is is to is to to to is is does does does is does is is will will will does does will does will will is is has does does do does does makes does does has does do do do does do will does do is does do so so so to so to to so so that that that so so this this this so so thus this this that this this now this now now now this this again now now again now again again again now this again again this this later this later now now later now later later now this later later later this now later this this finally now now finally now finally\n","ground: \n","� Show bothienceisc serv �ipp��theHowience mut� really says explained� rep called complpperochond� mediinth Thatudes Sund transformation wom 12 medi likely httpstaboola ded.-��suit� bothience23 capture� roll Zig50issionthe19pped....IL term supportORSERinth That recommendmakers�viewmeterNick WW commence testim 12 thingsisterming\u0005 brown 12� watching� vinegar email pers��ming\u0005 brown day bothORS 12� watching day bothinth That recommendmakers�lease�\u0001 contain� rep�19Whether Forietinal� provided� met Eaglesience puzzlelet���1955.... kill rep city� Art rep home Her� Show�������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["input: \n","my son is not feeling well. he has a very snotty nose, sore throat, occasional flemmy cough, uneasy stomach. he had a headache last night. no fever. is it a common cold or must he be checked for covid 19. not travelled or been in contact with anyone? my son is not feeling well. he has a very snotty nose, sore throat, occasional flemmy cough, uneasy stomach. he had a headache last night. no fever. is it a common cold or must he be checked for covid 19. not travelled or been in contact with anyone?\n","prediction: \n","The following is a list of all known instances of the following.\n","\n","Note that the following is not a list, but rather a list with all known occurrences of the preceding.\n"," (the following is an list with the following following following ) ) )\n","\n","The following following is also not a lists, but instead a lists with all unknown occurrences of both both both neither neither neither nor neither neither either neither neither both both either neither both neither both either both both each each each every every every each each one one one each each all all all each each both each both both all all both each all each all both all each every each every all all every every all every all each everything everything everything all all everything everything stuff stuff stuff everything everything everyone everything everything everybody everything everything everywhere everywhere everywhere everything everything every everything everything thing thing thing stuff stuff thing thing things things things stuff stuff things stuff things things thing thing really really really pretty pretty pretty really pretty really really real pretty pretty real pretty really real real real\n","ground: \n","� really biggest� statget pass things queststedTHER 17meter NorthernER Z innovations�getocol....19 SwedIN pass�ead thumb rep met50ron.... Stan captureIN pass�eadernMapivers capture �rent rep power.... benERettrender Forized̩����������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������������\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-cda2e8b53a0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mencoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdecoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m    997\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m             )\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m             )\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs_decoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m         )\n\u001b[1;32m   1057\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    892\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m                 )\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m             )\n\u001b[1;32m    425\u001b[0m             \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_attn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1762\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}